# Comprehensive cheatsheet data for all algorithms and data structures

sorting:
  title: "Sorting Algorithms"
  icon: "üîÑ"
  color: "#FF6B6B"
  algorithms:
    - name: "Bubble Sort"
      timeComplexity:
        best: "O(n)"
        average: "O(n¬≤)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: true
      inPlace: true
      description: "Repeatedly steps through the list, compares adjacent elements and swaps them if they are in wrong order."
      useCases:
        - "Small datasets"
        - "Educational purposes"
        - "Nearly sorted data"
      pros:
        - "Simple to understand"
        - "Easy to implement"
        - "Stable sort"
      cons:
        - "Very slow for large datasets"
        - "Many unnecessary comparisons"

    - name: "Insertion Sort"
      timeComplexity:
        best: "O(n)"
        average: "O(n¬≤)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: true
      inPlace: true
      description: "Builds the final sorted array one item at a time by inserting each element into its proper position."
      useCases:
        - "Small datasets"
        - "Nearly sorted data"
        - "Online sorting"
      pros:
        - "Efficient for small data"
        - "Adaptive"
        - "Stable"
        - "In-place"
      cons:
        - "Inefficient for large datasets"
        - "Quadratic time complexity"

    - name: "Selection Sort"
      timeComplexity:
        best: "O(n¬≤)"
        average: "O(n¬≤)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: false
      inPlace: true
      description: "Finds the minimum element from unsorted part and puts it at the beginning."
      useCases:
        - "Small datasets"
        - "Memory write is costly operation"
      pros:
        - "Simple implementation"
        - "Minimum number of swaps"
      cons:
        - "Inefficient for large lists"
        - "Not stable"

    - name: "Merge Sort"
      timeComplexity:
        best: "O(n log n)"
        average: "O(n log n)"
        worst: "O(n log n)"
      spaceComplexity: "O(n)"
      stable: true
      inPlace: false
      description: "Divide and conquer algorithm that divides input array into two halves, recursively sorts them, and merges."
      useCases:
        - "Large datasets"
        - "External sorting"
        - "Linked lists"
      pros:
        - "Guaranteed O(n log n)"
        - "Stable"
        - "Parallelizable"
      cons:
        - "Requires extra space"
        - "Slower for small datasets"

    - name: "Quick Sort"
      timeComplexity:
        best: "O(n log n)"
        average: "O(n log n)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(log n)"
      stable: false
      inPlace: true
      description: "Picks a pivot element and partitions array around it, recursively sorting sub-arrays."
      useCases:
        - "Large datasets"
        - "General purpose sorting"
        - "In-memory sorting"
      pros:
        - "Very fast in practice"
        - "In-place"
        - "Cache-friendly"
      cons:
        - "Not stable"
        - "Worst case O(n¬≤)"
        - "Recursive"

    - name: "Heap Sort"
      timeComplexity:
        best: "O(n log n)"
        average: "O(n log n)"
        worst: "O(n log n)"
      spaceComplexity: "O(1)"
      stable: false
      inPlace: true
      description: "Uses binary heap data structure to sort elements."
      useCases:
        - "When guaranteed O(n log n) needed"
        - "Priority queue"
      pros:
        - "Guaranteed O(n log n)"
        - "In-place"
        - "No worst case"
      cons:
        - "Not stable"
        - "Not cache-friendly"
        - "Slower than Quick Sort"

    - name: "Tim Sort"
      timeComplexity:
        best: "O(n)"
        average: "O(n log n)"
        worst: "O(n log n)"
      spaceComplexity: "O(n)"
      stable: true
      inPlace: false
      description: "Hybrid sorting algorithm combining merge sort and insertion sort."
      useCases:
        - "Python's built-in sort"
        - "Java's Arrays.sort"
        - "Real-world data"
      pros:
        - "Very fast on real data"
        - "Stable"
        - "Adaptive"
      cons:
        - "Complex implementation"
        - "Requires extra space"

    - name: "Radix Sort"
      timeComplexity:
        best: "O(nk)"
        average: "O(nk)"
        worst: "O(nk)"
      spaceComplexity: "O(n + k)"
      stable: true
      inPlace: false
      description: "Non-comparative sorting algorithm that sorts integers by processing digits."
      useCases:
        - "Integer sorting"
        - "Fixed-length strings"
        - "Large numbers"
      pros:
        - "Linear time for integers"
        - "Stable"
      cons:
        - "Only for integers/strings"
        - "Requires extra space"

    - name: "Bucket Sort"
      timeComplexity:
        best: "O(n + k)"
        average: "O(n + k)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(n + k)"
      stable: true
      inPlace: false
      description: "Distributes elements into buckets, then sorts each bucket."
      useCases:
        - "Uniformly distributed data"
        - "Floating point numbers"
      pros:
        - "Fast for uniform data"
        - "Stable"
      cons:
        - "Requires knowledge of data distribution"
        - "Extra space"

    - name: "Shell Sort"
      timeComplexity:
        best: "O(n log n)"
        average: "O(n log¬≤ n)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: false
      inPlace: true
      description: "Generalized insertion sort that allows exchange of far items."
      useCases:
        - "Medium-sized arrays"
        - "When space is limited"
      pros:
        - "Better than insertion sort"
        - "In-place"
      cons:
        - "Not stable"
        - "Complex analysis"

    - name: "Cycle Sort"
      timeComplexity:
        best: "O(n¬≤)"
        average: "O(n¬≤)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: false
      inPlace: true
      description: "In-place sorting that minimizes the number of writes to memory."
      useCases:
        - "Expensive write operations"
        - "EEPROM/Flash memory"
      pros:
        - "Minimum writes"
        - "In-place"
      cons:
        - "Slow"
        - "Complex implementation"

    - name: "Intro Sort"
      timeComplexity:
        best: "O(n log n)"
        average: "O(n log n)"
        worst: "O(n log n)"
      spaceComplexity: "O(log n)"
      stable: false
      inPlace: true
      description: "Hybrid of quicksort, heapsort, and insertion sort."
      useCases:
        - "C++ std::sort"
        - "General purpose sorting"
      pros:
        - "Guaranteed O(n log n)"
        - "Fast in practice"
      cons:
        - "Complex implementation"
        - "Not stable"

    - name: "Cocktail Shaker Sort"
      timeComplexity:
        best: "O(n)"
        average: "O(n¬≤)"
        worst: "O(n¬≤)"
      spaceComplexity: "O(1)"
      stable: true
      inPlace: true
      description: "Bidirectional bubble sort that traverses in both directions."
      useCases:
        - "Educational purposes"
        - "Small datasets"
      pros:
        - "Slightly better than bubble sort"
        - "Simple"
      cons:
        - "Still inefficient"
        - "Rarely used in practice"

searching:
  title: "Searching Algorithms"
  icon: "üîç"
  color: "#4ECDC4"
  algorithms:
    - name: "Linear Search"
      timeComplexity:
        best: "O(1)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(1)"
      description: "Sequentially checks each element until target is found or list ends."
      useCases:
        - "Unsorted data"
        - "Small datasets"
        - "Linked lists"
      pros:
        - "Works on unsorted data"
        - "Simple"
        - "No preprocessing"
      cons:
        - "Slow for large datasets"
        - "Linear time"

    - name: "Binary Search"
      timeComplexity:
        best: "O(1)"
        average: "O(log n)"
        worst: "O(log n)"
      spaceComplexity: "O(1)"
      description: "Divides search interval in half repeatedly. Requires sorted array."
      useCases:
        - "Large sorted datasets"
        - "Dictionary lookups"
      pros:
        - "Very fast"
        - "Logarithmic time"
      cons:
        - "Requires sorted data"
        - "Random access needed"

    - name: "Ternary Search"
      timeComplexity:
        best: "O(1)"
        average: "O(log‚ÇÉ n)"
        worst: "O(log‚ÇÉ n)"
      spaceComplexity: "O(1)"
      description: "Divides array into three parts and determines which section contains target."
      useCases:
        - "Unimodal functions"
        - "Finding maximum/minimum"
      pros:
        - "Fewer iterations than binary search"
      cons:
        - "More comparisons per iteration"
        - "Requires sorted data"

    - name: "Jump Search"
      timeComplexity:
        best: "O(1)"
        average: "O(‚àön)"
        worst: "O(‚àön)"
      spaceComplexity: "O(1)"
      description: "Jumps ahead by fixed steps, then linear search in block."
      useCases:
        - "Sorted arrays"
        - "When binary search overhead is high"
      pros:
        - "Better than linear"
        - "Works with any jump size"
      cons:
        - "Requires sorted data"
        - "Slower than binary search"

    - name: "Exponential Search"
      timeComplexity:
        best: "O(1)"
        average: "O(log n)"
        worst: "O(log n)"
      spaceComplexity: "O(1)"
      description: "Finds range where element exists, then binary search in that range."
      useCases:
        - "Unbounded/infinite arrays"
        - "Better than binary for nearby elements"
      pros:
        - "Good for unbounded searches"
        - "Efficient for nearby elements"
      cons:
        - "Requires sorted data"
        - "Two-phase approach"
        
    - name: "Fibonacci Search"
      timeComplexity:
        best: "O(1)"
        average: "O(log n)"
        worst: "O(log n)"
      spaceComplexity: "O(1)"
      description: "Uses Fibonacci numbers to narrow down search positions in a sorted array."
      useCases:
        - "Large arrays not in CPU cache"
        - "Systems where division is slow"
        - "Read-only memory"
      pros:
        - "Avoids division, uses +/-"
        - "Logarithmic time"
        - "Efficient for slow-access memory"
      cons:
        - "Requires sorted data"
        - "Slightly more complex than Binary Search"

dataStructures:
  title: "Data Structures"
  icon: "üóÇÔ∏è"
  color: "#95E1D3"
  structures:
    - name: "Array"
      timeComplexity:
        access: "O(1)"
        search: "O(n)"
        insertion: "O(n)"
        deletion: "O(n)"
      spaceComplexity: "O(n)"
      description: "Contiguous memory locations storing elements of same type."
      useCases:
        - "Random access needed"
        - "Fixed size data"
        - "Matrix operations"
      pros:
        - "Fast access"
        - "Cache friendly"
        - "Simple"
      cons:
        - "Fixed size"
        - "Expensive insertion/deletion"

    - name: "Linked List"
      timeComplexity:
        access: "O(n)"
        search: "O(n)"
        insertion: "O(1)"
        deletion: "O(1)"
      spaceComplexity: "O(n)"
      description: "Nodes connected via pointers, dynamic size."
      useCases:
        - "Dynamic size"
        - "Frequent insertions/deletions"
        - "Unknown size"
      pros:
        - "Dynamic size"
        - "Efficient insertion/deletion"
      cons:
        - "No random access"
        - "Extra memory for pointers"

    - name: "Stack"
      timeComplexity:
        push: "O(1)"
        pop: "O(1)"
        peek: "O(1)"
      spaceComplexity: "O(n)"
      description: "LIFO (Last In First Out) data structure."
      useCases:
        - "Function calls"
        - "Undo operations"
        - "Expression evaluation"
      pros:
        - "Simple"
        - "Fast operations"
        - "Memory efficient"
      cons:
        - "Limited access"
        - "Size limitations"

    - name: "Queue"
      timeComplexity:
        enqueue: "O(1)"
        dequeue: "O(1)"
        peek: "O(1)"
      spaceComplexity: "O(n)"
      description: "FIFO (First In First Out) data structure."
      useCases:
        - "BFS"
        - "Task scheduling"
        - "Print queue"
      pros:
        - "Fair ordering"
        - "Fast operations"
      cons:
        - "Limited access"
        - "Size limitations"

    - name: "Hash Table"
      timeComplexity:
        search: "O(1) avg"
        insertion: "O(1) avg"
        deletion: "O(1) avg"
      spaceComplexity: "O(n)"
      description: "Key-value pairs with hash function for indexing."
      useCases:
        - "Fast lookups"
        - "Caching"
        - "Dictionaries"
      pros:
        - "Very fast operations"
        - "Flexible keys"
      cons:
        - "Hash collisions"
        - "Unordered"
        - "Space overhead"

    - name: "Binary Search Tree"
      timeComplexity:
        search: "O(log n) avg"
        insertion: "O(log n) avg"
        deletion: "O(log n) avg"
      spaceComplexity: "O(n)"
      description: "Binary tree where left child < parent < right child."
      useCases:
        - "Ordered data"
        - "Range queries"
        - "Priority queues"
      pros:
        - "Ordered data"
        - "Fast operations"
        - "Dynamic"
      cons:
        - "Can become unbalanced"
        - "Complex implementation"

    - name: "AVL Tree"
      timeComplexity:
        search: "O(log n)"
        insertion: "O(log n)"
        deletion: "O(log n)"
      spaceComplexity: "O(n)"
      description: "Self-balancing BST with height difference ‚â§ 1."
      useCases:
        - "Frequent searches"
        - "Databases"
        - "File systems"
      pros:
        - "Always balanced"
        - "Guaranteed O(log n)"
      cons:
        - "Complex rotations"
        - "Extra space for height"

    - name: "Heap"
      timeComplexity:
        findMin: "O(1)"
        insertion: "O(log n)"
        deletion: "O(log n)"
      spaceComplexity: "O(n)"
      description: "Complete binary tree with heap property (min/max)."
      useCases:
        - "Priority queues"
        - "Heap sort"
        - "Graph algorithms"
      pros:
        - "Fast min/max access"
        - "Efficient priority queue"
      cons:
        - "No fast search"
        - "Complex implementation"

    - name: "Trie"
      timeComplexity:
        search: "O(m)"
        insertion: "O(m)"
        deletion: "O(m)"
      spaceComplexity: "O(ALPHABET_SIZE * m * n)"
      description: "Tree for storing strings, prefix-based structure."
      useCases:
        - "Autocomplete"
        - "Spell checkers"
        - "IP routing"
      pros:
        - "Fast prefix search"
        - "Memory efficient for common prefixes"
      cons:
        - "Large space for sparse data"
        - "Complex implementation"

    - name: "Graph (Adjacency List)"
      timeComplexity:
        addVertex: "O(1)"
        addEdge: "O(1)"
        removeEdge: "O(E)"
      spaceComplexity: "O(V + E)"
      description: "Vertices connected by edges, using list representation."
      useCases:
        - "Social networks"
        - "Maps"
        - "Web crawling"
      pros:
        - "Space efficient for sparse graphs"
        - "Fast iteration"
      cons:
        - "Slow edge lookup"
        - "Complex for dense graphs"

graph:
  title: "Graph Algorithms"
  icon: "üï∏Ô∏è"
  color: "#F38181"
  algorithms:
    - name: "Breadth-First Search (BFS)"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Explores neighbors level by level using a queue."
      useCases:
        - "Shortest path unweighted"
        - "Level order traversal"
        - "Web crawling"
      pros:
        - "Finds shortest path"
        - "Complete search"
        - "Simple"
      cons:
        - "Uses more memory"
        - "Not optimal for weighted graphs"

    - name: "Depth-First Search (DFS)"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Explores as far as possible along each branch using stack."
      useCases:
        - "Cycle detection"
        - "Topological sorting"
        - "Maze solving"
      pros:
        - "Memory efficient"
        - "Detects cycles"
        - "Topological sort"
      cons:
        - "May not find shortest path"
        - "Can get stuck in infinite loops"

    - name: "Dijkstra's Algorithm"
      timeComplexity:
        best: "O((V + E) log V)"
        average: "O((V + E) log V)"
        worst: "O((V + E) log V)"
      spaceComplexity: "O(V)"
      description: "Finds shortest path in weighted graph with non-negative weights."
      useCases:
        - "GPS navigation"
        - "Network routing"
        - "Shortest path problems"
      pros:
        - "Optimal paths"
        - "Works with weighted graphs"
      cons:
        - "Doesn't work with negative weights"
        - "Slower than BFS"

    - name: "A* Algorithm"
      timeComplexity:
        best: "O(E)"
        average: "O(E)"
        worst: "O(V * E)"
      spaceComplexity: "O(V)"
      description: "Heuristic-based shortest path algorithm."
      useCases:
        - "Pathfinding in games"
        - "Route planning"
        - "Robotics"
      pros:
        - "Faster than Dijkstra with good heuristic"
        - "Optimal"
      cons:
        - "Requires good heuristic"
        - "Memory intensive"

    - name: "Prim's Algorithm"
      timeComplexity:
        best: "O(E log V)"
        average: "O(E log V)"
        worst: "O(E log V)"
      spaceComplexity: "O(V)"
      description: "Finds minimum spanning tree by growing tree from starting vertex."
      useCases:
        - "Network design"
        - "Clustering"
        - "Approximation algorithms"
      pros:
        - "Efficient for dense graphs"
        - "Simple implementation"
      cons:
        - "Requires connected graph"
        - "Greedy approach"

    - name: "Kruskal's Algorithm"
      timeComplexity:
        best: "O(E log E)"
        average: "O(E log E)"
        worst: "O(E log E)"
      spaceComplexity: "O(V)"
      description: "Finds MST by sorting edges and adding smallest edge that doesn't create cycle."
      useCases:
        - "Network design"
        - "Clustering"
        - "Image segmentation"
      pros:
        - "Works for disconnected graphs"
        - "Easy to implement"
      cons:
        - "Requires sorting edges"
        - "Uses union-find"

#Added Segment Tree
    - name: "Segment Tree"
      timeComplexity:
        best: "O(log N)"
        average: "O(log N)"
        worst: "O(log N)"
      spaceComplexity: "O(4N)"
      description: "A binary tree data structure that allows efficient range queries and updates (like sum, min, max, or gcd) on arrays."
      useCases:
        - "Range sum queries"
        - "Range minimum/maximum queries"
        - "Range updates (lazy propagation)"
        - "Prefix/suffix computations"
      pros:
        - "Supports both queries and updates in logarithmic time"
        - "Highly customizable for different associative operations"
        - "Can be extended for lazy propagation to handle range updates efficiently"
      cons:
        - "High memory usage (~4N)"
        - "Complex to implement correctly"
        - "Overkill for static (non-updated) data"

# Added Fenwick Tree
    - name: "Fenwick Tree"
      timeComplexity:
        best: "O(log N)"
        average: "O(log N)"
        worst: "O(log N)"
      spaceComplexity: "O(N)"
      description: "A data structure that efficiently supports prefix sum and update operations using bit manipulation to traverse index ranges."
      useCases:
        - "Prefix sum queries"
        - "Dynamic range sum queries"
        - "Inversion count problems"
        - "Cumulative frequency tables"
      pros:
        - "Simpler and more space-efficient than Segment Tree"
        - "Fast O(log N) prefix and update operations"
        - "Elegant implementation using bit manipulation"
      cons:
        - "Limited to operations that can be represented as prefix-based (e.g., sum)"
        - "Cannot handle complex range updates without additional logic"
        - "Harder to visualize than Segment Tree"

#Topological Sort
    - name: "Topological Sort"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Linear ordering of vertices in a directed acyclic graph (DAG) such that for every directed edge (u ‚Üí v), vertex u appears before vertex v."
      useCases:
        - "Task scheduling with dependencies"
        - "Build systems (resolving compilation order)"
        - "Course prerequisite problems"
        - "Dependency resolution in DAGs"
      pros:
        - "Detects cycles in directed graphs"
        - "Efficient for DAG-based dependency problems"
        - "Useful in many real-world scheduling systems"
      cons:
        - "Only works for Directed Acyclic Graphs (DAGs)"
        - "Does not provide path or distance information"
        - "Multiple valid orders may exist"

#Bellman Ford
    - name: "Bellman-Ford Algorithm"
      timeComplexity:
        best: "O(E)"
        average: "O(V * E)"
        worst: "O(V * E)"
      spaceComplexity: "O(V)"
      description: "Computes shortest paths from a single source to all vertices in a weighted graph, with negative weights edges."
      useCases:
        - "Shortest path in graphs with negative edges"
        - "Detecting negative weight cycles"
        - "Currency arbitrage or financial graph problems"
        - "Routing algorithms in dynamic networks"
      pros:
        - "Handles negative edge weights"
        - "Simple and easy to implement"
        - "Detects negative cycles effectively"
      cons:
        - "Slower than Dijkstra`s for graphs without negative edges"
        - "Not efficient for dense graphs"
        - "Higher time complexity which is (O(V * E))"

#Floyd-warshall algo
    - name: "Floyd-Warshall Algorithm"
      timeComplexity:
        best: "O(V¬≥)"
        average: "O(V¬≥)"
        worst: "O(V¬≥)"
      spaceComplexity: "O(V¬≤)"
      description: "DP algorithm for graph to find the shortest paths between all pairs of vertices in a weighted graph with negative weights ( but no negative cycles)."
      useCases:
        - "All-pairs shortest path computation"
        - "Routing algorithms"
        - "Transitive closure of a graph"
        - "Network analysis and reachability"
      pros:
        - "Finds shortest paths between all vertex pairs"
        - "Works with negative weights (no negative cycles)"
        - "Simple matrix-based implementation"
      cons:
        - "High time complexity (O(V¬≥))"
        - "Consumes large memory for dense graphs"
        - "Not ideal for very large graphs"

#Tarzen algorithm
    - name: "Tarjan‚Äôs Algorithm"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Efficient algorithm to find all strongly connected components (SCCs) in a directed graph using a single DFS traversal and low-link values."
      useCases:
        - "Finding Strongly Connected Components (SCCs)"
        - "Detecting cycles in directed graphs"
        - "Optimizing dependency resolution"
        - "Finding articulation points in networks"
      pros:
        - "Single DFS traversal ‚Äî highly efficient"
        - "No need to reverse the graph"
        - "Linear time for SCC computation"
      cons:
        - "Complex to implement and debug"
        - "Requires stack and recursion tracking"
        - "Works only for directed graphs"

#Kosaraju's algorithm
    - name: "Kosaraju's Algorithm"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Algorithm to find strongly connected components (SCCs) in a directed graph using two DFS passes ‚Äî one on the original graph and one on its transpose."
      useCases:
        - "Finding Strongly Connected Components (SCCs)"
        - "Cycle detection in directed graphs"
        - "Topological sorting of SCCs"
        - "Analyzing connectivity in networks"
      pros:
        - "Conceptually simple and easy to reason about"
        - "Linear time complexity"
        - "Intuitive approach using graph transposition"
      cons:
        - "Requires two full DFS traversals"
        - "Needs additional memory for transpose graph"
        - "Less efficient than Tarjan's in practice"

#Johnsan's algo
    - name: "Johnson`s Algorithm"
      timeComplexity:
        best: "O(V¬≤ log V + V * E)"
        average: "O(V¬≤ log V + V * E)"
        worst: "O(V¬≤ log V + V * E)"
      spaceComplexity: "O(V¬≤)"
      description: "Finds shortest paths between all pairs of vertices in a weighted, directed graph, even with negative edge weights, using Bellman-Ford and Dijkstra‚Äôs algorithms together."
      useCases:
        - "All-pairs shortest path in sparse graphs"
        - "Graphs with negative edge weights (no negative cycles)"
        - "Network routing and optimization"
        - "Graph analysis where both Bellman-Ford and Dijkstra can be combined"
      pros:
        - "Efficient for sparse graphs compared to Floyd-Warshall"
        - "Handles negative weights gracefully"
        - "Combines the power of Dijkstra and Bellman-Ford"
      cons:
        - "More complex to implement"
        - "Not ideal for dense graphs"
        - "Fails if graph contains negative cycles"

#Ford-fulkerson algo
    - name: "Ford-Fulkerson Algorithm"
      timeComplexity:
        best: "O(E * max_flow)"
        average: "O(E * max_flow)"
        worst: "O(E * max_flow)"
      spaceComplexity: "O(V + E)"
      description: "Computes the maximum flow in a flow network using the concept of augmenting paths and residual capacities."
      useCases:
        - "Maximum flow problems"
        - "Network routing and bandwidth allocation"
        - "Bipartite matching"
        - "Circulation and cut problems in graphs"
      pros:
        - "Simple and intuitive approach"
        - "Can handle large flow networks"
        - "Foundation for Edmonds-Karp and Dinic's algorithms"
      cons:
        - "Runtime depends on the magnitude of max flow"
        - "May not terminate for irrational capacities"
        - "Less efficient for dense or large graphs"

#Kahn's algo
    - name: "Kahn`s Algorithm"
      timeComplexity:
        best: "O(V + E)"
        average: "O(V + E)"
        worst: "O(V + E)"
      spaceComplexity: "O(V)"
      description: "Performs topological sorting on a Directed Acyclic Graph (DAG) using in-degree calculation and a queue to process nodes with zero in-degree."
      useCases:
        - "Topological sorting of DAGs"
        - "Task scheduling and dependency resolution"
        - "Detecting cycles in directed graphs"
        - "Build systems and prerequisite problems"
      pros:
        - "Iterative and easy to understand"
        - "Detects cycles in directed graphs"
        - "Efficient linear-time implementation"
      cons:
        - "Works only on DAGs"
        - "Not suitable for dynamic graphs"
        - "Requires maintenance of in-degree array"

# Tree algorithms for the cheatsheet added
trees:
  title: "Tree Algorithms"
  icon: "üå≥"
  color: "#8BC34A"
  algorithms:
    - name: "Binary Tree Traversal (Inorder)"
      timeComplexity:
        best: "O(n)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(h)"
      description: "Visits left subtree, root, then right subtree recursively."
      useCases:
        - "BST sorted order traversal"
        - "Expression tree evaluation"
        - "Flatten tree to sorted array"
      pros:
        - "Natural sorted order for BST"
        - "Simple recursive implementation"
      cons:
        - "Requires stack space"
        - "Not suitable for non-BST ordering"

    - name: "Binary Tree Traversal (Preorder)"
      timeComplexity:
        best: "O(n)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(h)"
      description: "Visits root first, then left subtree, then right subtree."
      useCases:
        - "Tree copying/cloning"
        - "Prefix expression generation"
        - "Tree serialization"
      pros:
        - "Good for copying trees"
        - "Root processed first"
      cons:
        - "Not sorted order for BST"
        - "Stack space required"

    - name: "Binary Tree Traversal (Postorder)"
      timeComplexity:
        best: "O(n)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(h)"
      description: "Visits left subtree, right subtree, then root."
      useCases:
        - "Tree deletion"
        - "Postfix expression evaluation"
        - "Calculate directory sizes"
      pros:
        - "Children processed before parent"
        - "Good for deletion operations"
      cons:
        - "Root processed last"
        - "Requires stack space"

    - name: "Level Order Traversal (BFS)"
      timeComplexity:
        best: "O(n)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(w)"
      description: "Visits nodes level by level using a queue."
      useCases:
        - "Level-wise processing"
        - "Find tree width"
        - "Connect nodes at same level"
      pros:
        - "Natural level-by-level order"
        - "No recursion needed"
      cons:
        - "Uses queue space"
        - "Not sorted for BST"

    - name: "Lowest Common Ancestor (LCA)"
      timeComplexity:
        best: "O(log n)"
        average: "O(h)"
        worst: "O(n)"
      spaceComplexity: "O(h)"
      description: "Finds the lowest common ancestor of two nodes in a tree."
      useCases:
        - "Finding distance between nodes"
        - "Range queries in trees"
        - "Hierarchical relationships"
      pros:
        - "Efficient for balanced trees"
        - "Fundamental tree operation"
      cons:
        - "Can be O(n) for skewed trees"
        - "Requires parent pointers or recursion"

    - name: "Morris Traversal"
      timeComplexity:
        best: "O(n)"
        average: "O(n)"
        worst: "O(n)"
      spaceComplexity: "O(1)"
      description: "Traverses tree without recursion or stack by creating temporary links."
      useCases:
        - "Space-constrained environments"
        - "Inorder traversal without stack"
        - "Constant space traversal"
      pros:
        - "O(1) space complexity"
        - "No recursion or stack"
      cons:
        - "Modifies tree temporarily"
        - "More complex implementation"
        - "Not intuitive"


advancedAlgorithms:
  title: "Advanced Techniques"
  icon: "üß†"
  color: "#AA96DA"
  techniques:
    - name: "Dynamic Programming"
      category: "Paradigm"
      description: "Solves complex problems by breaking them down into simpler subproblems."
      keyPoints:
        - "Optimal substructure"
        - "Overlapping subproblems"
        - "Memoization or tabulation"
        - "Bottom-up or top-down approach"
      examples:
        - "Fibonacci"
        - "Knapsack"
        - "Longest Common Subsequence"
        - "Edit Distance"
      whenToUse:
        - "Optimization problems"
        - "Counting problems"
        - "Overlapping subproblems"

    - name: "Greedy Algorithms"
      category: "Paradigm"
      description: "Makes locally optimal choice at each step hoping to find global optimum."
      keyPoints:
        - "Greedy choice property"
        - "Optimal substructure"
        - "No backtracking"
        - "Fast execution"
      examples:
        - "Huffman Coding"
        - "Activity Selection"
        - "Fractional Knapsack"
        - "Dijkstra"
      whenToUse:
        - "Optimization problems"
        - "When greedy choice is safe"
        - "Need fast solution"

    - name: "Backtracking"
      category: "Paradigm"
      description: "Explores all possible solutions by incrementally building candidates."
      keyPoints:
        - "Recursive approach"
        - "Abandons candidates when they cannot lead to solution"
        - "DFS-like exploration"
        - "Constraint satisfaction"
      examples:
        - "N-Queens"
        - "Sudoku Solver"
        - "Hamiltonian Path"
        - "Subset Sum"
      whenToUse:
        - "Constraint satisfaction"
        - "Combinatorial problems"
        - "Finding all solutions"

    - name: "Divide and Conquer"
      category: "Paradigm"
      description: "Divides problem into smaller subproblems, solves them, and combines results."
      keyPoints:
        - "Divide into subproblems"
        - "Conquer subproblems recursively"
        - "Combine solutions"
        - "Often logarithmic depth"
      examples:
        - "Merge Sort"
        - "Quick Sort"
        - "Binary Search"
        - "Strassen's Matrix"
      whenToUse:
        - "Problem can be divided"
        - "Subproblems are independent"
        - "Parallelizable"

    - name: "Branch and Bound"
      category: "Optimization"
      description: "Systematically enumerates candidates by exploring branches of state space."
      keyPoints:
        - "Uses bounding functions"
        - "Prunes search space"
        - "Optimal solution guaranteed"
        - "Memory intensive"
      examples:
        - "Traveling Salesman"
        - "0/1 Knapsack"
        - "Job Assignment"
      whenToUse:
        - "Exact optimization needed"
        - "Can compute bounds"
        - "Small to medium problems"

    - name: "Hashing"
      category: "Technique"
      description: "Maps data to fixed-size values using hash function."
      keyPoints:
        - "O(1) average lookup"
        - "Hash collisions"
        - "Load factor"
        - "Collision resolution"
      examples:
        - "Hash Tables"
        - "Rabin-Karp"
        - "Bloom Filters"
        - "Consistent Hashing"
      whenToUse:
        - "Fast lookups needed"
        - "Caching"
        - "Duplicate detection"
        - "Sets/Maps"

  # Added Game theory 
    - name: "Game Theory"
      category: "Technique"
      description: "Mathematical framework to analyze strategic interactions between two-more players making optimal moves."
      keyPoints:
        - "Zero-sum and non-zero-sum games"
        - "Optimal strategies and equilibrium points"
        - "Minimax principle"
        - "Nim and Grundy numbers (Sprague-Grundy theorem)"
        - "Winning vs Losing positions"
        - "Combinatorial game theory"
      examples:
        - "Nim Game"
        - "Grundy Numbers"
        - "Tic-Tac-Toe (Minimax Algorithm)"
        - "Coin Game / Stone Game variations"
        - "Matrix Games"
      whenToUse:
        - "Two players alternate moves with complete information"
        - "Each move changes game state deterministically"
        - "You need to determine if the first or second player has a winning strategy"
        - "Problems involving removal/addition of elements (piles, coins, stones)"
        - "Competitive turn-based decision problems"
      importantFormulas:
        - "Grundy number of a position = mex({Grundy numbers of reachable states})"
        - "If XOR of all pile Grundy numbers = 0 ‚Üí losing position"
        - "Else ‚Üí winning position"
      patterns:
        - "Nim-like games (XOR-based analysis)"
        - "DP on game states"
        - "Minimax with memoization"
        - "Impartial vs Partisan games classification"
      complexity:
        time: "Varies ‚Äî O(state transitions) or O(n) for classic Nim-type games"
        space: "O(number of states)"

  # Added Number Theory
    - name: "Number Theory"
      category: "Technique"
      description: "Applies mathematical principles to solve computational and modular problems efficiently, used in cryptography, combinatorics, and competitive programming."
      keyPoints:
        - "Modular Arithmetic (mod properties, inverse mod)"
        - "Prime Numbers & Sieve of Eratosthenes"
        - "GCD & LCM"
        - "Modular Exponentiation"
        - "Fermat‚Äôs Little Theorem"
        - "Euler‚Äôs Totient Function"
        - "Chinese Remainder Theorem"
      examples:
        - "Count of Prime Numbers up to N"
        - "Modular Multiplicative Inverse of a Number"
        - "Big Modulo Exponentiation (a^b % M)"
        - "Number of Divisors of N"
      whenToUse:
        - "When dealing with large numbers under modulo (10^9+7 or similar)"
        - "When you need to compute powers, inverses, or combinations efficiently"
        - "When problems involve divisibility, primes, or modular relationships"
        - "When optimizing mathematical or combinatorial computations"
      importantFormulas:
        - "GCD(a, b) = GCD(b, a % b)"
        - "a^(b) % m ‚Üí use Binary Exponentiation for O(log b)"
        - "Fermats Theorem: a^(m-1) ‚â° 1 (mod m) if m is prime"
        - "Modular Inverse: a^(m-2) % m (when m is prime)"
      patterns:
        - "Prime-based optimization (precompute primes using Sieve)"
        - "Combinatorics with modular arithmetic (nCr % mod)"
        - "Mathematical counting problems"
        - "Modular inverse and fast exponentiation patterns"
      complexity:
        time: "O(n log log n) for sieve; O(log n) for modular operations"
        space: "O(n) for precomputed arrays (like primes or factorials)"

# Added Sliding Window
    - name: "Sliding Window"
      category: "Technique"
      description: "A technique to efficiently solve problems involving contiguous subarrays or substrings by maintaining a window of elements and moving it across the data structure."
      keyPoints:
        - "Fixed-size sliding window"
        - "Variable-size sliding window"
        - "Cumulative sum / running sum"
        - "Two-pointer approach within the window"
        - "Optimizing nested loops to linear time"
        - "Variable length window size problems"
      examples:
        - "Maximum sum subarray of size K"
        - "Longest substring without repeating characters"
        - "Minimum size subarray sum ‚â• S"
        - "Sliding window maximum / minimum"
        - "Count of anagrams of a pattern in a string"
      whenToUse:
        - "When problem involves contiguous elements in arrays or strings"
        - "When brute-force nested loops are too slow (O(n¬≤))"
        - "When looking for sums, counts, or patterns within subarrays or substrings"
        - "When tracking min/max or frequency of elements in a window"
      importantFormulas:
        - "Sum of window: maintain running sum; add new element, remove exiting element"
        - "Frequency map for characters/numbers in window"
        - "Window size = right - left + 1"
        - "Check condition while moving left pointer in variable-size window"
      patterns:
        - "Fixed-size window: often used for max/min sum or average of subarray of size K"
        - "Variable-size window: often used for at-least/at-most conditions (like sum ‚â• S)"
        - "Sliding window with hash map: for distinct elements, anagrams, substring patterns"
        - "Two pointers within a window for dynamic constraints"
      complexity:
        time: "O(n) for most single-pass sliding window problems"
        space: "O(k) for frequency maps or auxiliary data structures, O(1) for simple sum/count"

# Added Bit Manipulation
    - name: "Bit Manipulation"
      category: "Technique"
      description: "Technique that leverages bitwise operators to perform operations on binary representations of numbers for optimizing arithmetic, logical, and set-based computations."
      keyPoints:
        - "Bitwise Operators: AND (&), OR (|), XOR (^), NOT (~), Left Shift (<<), Right Shift (>>)"
        - "Set, unset, toggle, and check bits using masks"
        - "Count set bits (Brian Kernighan‚Äôs algorithm, __builtin_popcount)"
        - "Check power of two using (n & (n-1)) == 0"
        - "Find unique elements using XOR property"
        - "Subsets generation using bitmasking"
        - "Manipulating bits for optimization in DP and combinatorics"
      examples:
        - "Find the single non-repeating element in an array where others appear twice"
        - "Count number of 1s in binary representation of a number"
        - "Check if a number is power of two"
        - "Generate all subsets of a set using bitmasking"
        - "Find two non-repeating elements in array where others appear twice"
        - "Reverse bits of a number"
      whenToUse:
        - "When optimizing arithmetic or logical operations"
        - "When problem constraints involve parity, power-of-two, or uniqueness"
        - "When generating subsets or solving DP on subsets (bitmask DP)"
        - "When you need to represent or manipulate multiple states efficiently"
      importantFormulas:
        - "Set bit: num | (1 << i)"
        - "Unset bit: num & ~(1 << i)"
        - "Toggle bit: num ^ (1 << i)"
        - "Check bit: (num >> i) & 1"
        - "Count set bits: while (n) { n &= (n - 1); count++; }"
        - "Check power of two: (n > 0) and (n & (n - 1)) == 0"
        - "XOR property: a ^ a = 0, a ^ 0 = a"
      patterns:
        - "Unique element problems using XOR"
        - "Counting bits and bit masking DP problems"
        - "Subsets generation using bitmask representation"
        - "Optimizing combinatorial or state-space problems"
        - "Binary representation tricks for parity and toggling"
      complexity:
        time: "O(1) for most bit operations; O(log n) when iterating over bits or subsets"
        space: "O(1) for normal use; O(2^n) when using bitmask DP or subsets generation"

# Added String Algorithms
    - name: "String Algorithms"
      category: "Technique"
      description: "A collection of algorithms & techniques used to efficiently manipulate strings, often involving pattern matching, hashing, and prefix computations."
      keyPoints:
        - "Pattern matching algorithms (KMP, Rabin-Karp, Z Algorithm)"
        - "Prefix function (œÄ array) and LPS array computation"
        - "String hashing (Rolling Hash, Polynomial Hash)"
        - "Trie data structure for prefix-based operations"
        - "Suffix Array and Suffix Tree concepts"
        - "Manacher‚Äôs Algorithm for longest palindromic substring"
        - "Two-pointer and sliding window techniques for substrings"
      examples:
        - "Find the first occurrence of a pattern in a string (KMP / Rabin-Karp)"
        - "Find the longest prefix which is also a suffix"
        - "Count distinct substrings using hashing or trie"
        - "Check if two strings are anagrams"
        - "Longest palindromic substring (Manacher‚Äôs)"
        - "Longest common prefix among words"
      whenToUse:
        - "When dealing with substring search, repetition, or matching problems"
        - "When optimizing naive O(n*m) substring comparisons"
        - "When needing to handle prefix, suffix, or pattern queries efficiently"
        - "When working with hashing for string comparison or substring uniqueness"
      importantFormulas:
        - "LPS (Longest Prefix Suffix): used in KMP preprocessing"
        - "Rolling Hash: hash(s) = (s[0]*p^(n-1) + s[1]*p^(n-2) + ... + s[n-1]) % mod"
        - "Z-Algorithm: Z[i] = length of longest substring starting at i which is also a prefix"
        - "Manacher‚Äôs: uses center expansion with transformed string for O(n) palindrome finding"
        - "String comparison via hash: hash1(l, r) == hash2(l, r) ‚Üí same substring"
      patterns:
        - "Pattern matching: KMP, Rabin-Karp, Z-Algorithm"
        - "Prefix-based problems: tries, prefix/suffix arrays"
        - "Palindrome-related: Manacher‚Äôs, expand around center"
        - "String hashing for duplicate substring detection"
        - "Character frequency or window-based problems"
      complexity:
        time: "O(n) for KMP/Z/Manacher‚Äôs; O(n log n) for suffix array; O(n*m) for naive search"
        space: "O(n) for prefix/hash arrays; O(1) for in-place algorithms"


bigOReference:
  title: "Big-O Complexity Chart"
  complexities:
    - notation: "O(1)"
      name: "Constant"
      color: "#00C853"
      description: "Best possible. Time doesn't change with input size."
      examples:
        - "Array access"
        - "Hash table lookup"
        - "Stack push/pop"

    - notation: "O(log n)"
      name: "Logarithmic"
      color: "#64DD17"
      description: "Excellent. Doubles input, adds constant time."
      examples:
        - "Binary search"
        - "Balanced tree operations"

    - notation: "O(n)"
      name: "Linear"
      color: "#FFD600"
      description: "Good. Time grows linearly with input."
      examples:
        - "Linear search"
        - "Array traversal"

    - notation: "O(n log n)"
      name: "Linearithmic"
      color: "#FF6D00"
      description: "Fair. Most efficient comparison sorts."
      examples:
        - "Merge sort"
        - "Quick sort (average)"
        - "Heap sort"

    - notation: "O(n¬≤)"
      name: "Quadratic"
      color: "#FF3D00"
      description: "Bad. Nested loops over input."
      examples:
        - "Bubble sort"
        - "Selection sort"
        - "Insertion sort"

    - notation: "O(2‚Åø)"
      name: "Exponential"
      color: "#D50000"
      description: "Very bad. Doubles with each input increase."
      examples:
        - "Recursive Fibonacci"
        - "Power set generation"

    - notation: "O(n!)"
      name: "Factorial"
      color: "#AA00FF"
      description: "Terrible. Avoid if possible."
      examples:
        - "Permutation generation"
        - "Traveling salesman (brute force)"

algorithmTips:
  - category: "Problem Solving"
    tips:
      - "Understand the problem before coding"
      - "Consider edge cases and constraints"
      - "Think about time and space complexity"
      - "Start with brute force, then optimize"
      - "Test with small examples first"

  - category: "Optimization"
    tips:
      - "Use hash tables for O(1) lookups"
      - "Consider two-pointer technique"
      - "Use sliding window for subarrays"
      - "Binary search for sorted data"
      - "Memoization for overlapping subproblems"

  - category: "Common Patterns"
    tips:
      - "Frequency counter pattern"
      - "Multiple pointers pattern"
      - "Sliding window pattern"
      - "Divide and conquer pattern"
      - "Dynamic programming pattern"
